{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8265895953757225\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"car_evaluation.csv\")\n",
    "\n",
    "\n",
    "data['buying price'] = data['buying price'].astype('category').cat.codes\n",
    "data['maintenance cost'] = data['maintenance cost'].astype('category').cat.codes\n",
    "data['number of doors'] = data['number of doors'].astype('category').cat.codes\n",
    "data['number of persons'] = data['number of persons'].astype('category').cat.codes\n",
    "data['lug_boot'] = data['lug_boot'].astype('category').cat.codes\n",
    "data['safety'] = data['safety'].astype('category').cat.codes\n",
    "data['decision'] = data['decision'].astype('category').cat.codes\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "\n",
    "def calculate_gini_impurity(labels):\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / len(labels)\n",
    "    gini_impurity = 1 - np.sum(probabilities**2)\n",
    "    return gini_impurity\n",
    "\n",
    "\n",
    "\n",
    "def find_best_split(data): #best split\n",
    "    best_gini = 1\n",
    "    best_split = None\n",
    "    features = data.columns[:-1]\n",
    "\n",
    "    for feature in features:\n",
    "        unique_values = data[feature].unique()\n",
    "        for value in unique_values:\n",
    "            left_data = data[data[feature] <= value]\n",
    "            right_data = data[data[feature] > value]\n",
    "            left_gini = calculate_gini_impurity(left_data['decision'])\n",
    "            right_gini = calculate_gini_impurity(right_data['decision'])\n",
    "            weighted_gini = (len(left_data) / len(data)) * \\\n",
    "                left_gini + (len(right_data) / len(data)) * right_gini\n",
    "            if weighted_gini < best_gini:\n",
    "                best_gini = weighted_gini\n",
    "                best_split = (feature, value)\n",
    "\n",
    "    return best_split\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature = None\n",
    "        self.value = None\n",
    "        self.label = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        unique_labels = data['decision'].unique()\n",
    "        if len(unique_labels) == 1:\n",
    "            self.label = unique_labels[0]\n",
    "            return\n",
    "        best_split = find_best_split(data)\n",
    "        if best_split is None:\n",
    "            self.label = unique_labels[np.argmax(\n",
    "                np.bincount(data['decision']))]\n",
    "            return\n",
    "        self.feature, self.value = best_split\n",
    "        left_data = data[data[self.feature] <= self.value]\n",
    "        right_data = data[data[self.feature] > self.value]\n",
    "        self.left = DecisionTree()\n",
    "        self.left.fit(left_data)\n",
    "        self.right = DecisionTree()\n",
    "        self.right.fit(right_data)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.label is not None:\n",
    "            return self.label\n",
    "        if x[self.feature] <= self.value:\n",
    "            return self.left.predict(x)\n",
    "        else:\n",
    "            return self.right.predict(x)\n",
    "\n",
    "\n",
    "tree = DecisionTree()\n",
    "tree.fit(train_data)\n",
    "\n",
    "correct = 0\n",
    "total = len(test_data)\n",
    "for index, row in test_data.iterrows():\n",
    "    prediction = tree.predict(row)\n",
    "    if prediction == row['decision']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average Accuracy over 5-fold Cross-Validation with k=5: 0.8324637681159419\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "fold_size = len(data) // num_folds\n",
    "validation_size = 0.1\n",
    "accuracies = []\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    start = fold * fold_size\n",
    "    end = (fold + 1) * fold_size\n",
    "    validation_data = data[start:end]\n",
    "    train_data = pd.concat([data[:start], data[end:]])\n",
    "\n",
    "    tree = DecisionTree()\n",
    "    tree.fit(train_data)\n",
    "\n",
    "    correct = 0\n",
    "    total = len(validation_data)\n",
    "    for index, row in validation_data.iterrows():\n",
    "        prediction = tree.predict(row)\n",
    "        if prediction == row['decision']:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(\" Average Accuracy over 5-fold Cross-Validation :\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2\n",
    "KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Classifier with k=5: 0.96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "data = pd.read_csv(\"car_evaluation.csv\")\n",
    "\n",
    "def categorical_to_numerical(data):\n",
    "    category_map = {}\n",
    "    for column in data.columns:\n",
    "        unique_values = data[column].unique()\n",
    "        category_map[column] = {value: idx for idx,value in enumerate(unique_values)}\n",
    "        data[column] = data[column].map(category_map[column])\n",
    "    return data, category_map\n",
    "\n",
    "\n",
    "data, category_map = categorical_to_numerical(data)\n",
    "\n",
    "def train_test_split(data, test_size=0.2):\n",
    "    num_samples = len(data)\n",
    "    test_samples = int(test_size * num_samples)\n",
    "    shuffled_indices = np.random.permutation(num_samples)\n",
    "    test_indices = shuffled_indices[:test_samples]\n",
    "    train_indices = shuffled_indices[test_samples:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(data)\n",
    "\n",
    "def knn_classifier(train_data, test_data, k=5):\n",
    "    predictions = []\n",
    "    for _, test_instance in test_data.iterrows():\n",
    "        distances = []\n",
    "        for _, train_instance in train_data.iterrows():\n",
    "            euclidean_distance = np.linalg.norm(\n",
    "                test_instance[:-1] - train_instance[:-1])\n",
    "            distances.append((euclidean_distance, train_instance[-1]))\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_nearest_neighbors = distances[:k]\n",
    "        neighbor_labels = [neighbor[1] for neighbor in k_nearest_neighbors]\n",
    "        most_common_label = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "        predictions.append(most_common_label)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "k = 5 \n",
    "predictions = knn_classifier(train_data, test_data, k)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "\n",
    "test_labels = test_data['decision'].values\n",
    "accuracy_score = accuracy(test_labels, predictions)\n",
    "print(f\"Accuracy of KNN Classifier with k={k}: {accuracy_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy over 5-fold Cross-Validation with k=5: 0.95\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "num_folds = 5\n",
    "validation_size = 0.1\n",
    "fold_size = int(len(data) / num_folds)\n",
    "folds = []\n",
    "for i in range(num_folds):\n",
    "    start_idx = i * fold_size\n",
    "    end_idx = start_idx + fold_size\n",
    "    if i == num_folds - 1:\n",
    "        end_idx = len(data)\n",
    "    fold = data[start_idx:end_idx]\n",
    "    folds.append(fold)\n",
    "    \n",
    "accuracies = []\n",
    "for i in range(num_folds):\n",
    "    validation_data = folds[i]\n",
    "    train_data = pd.concat([fold for j, fold in enumerate(folds) if j != i])\n",
    "\n",
    "    k = 5  \n",
    "    predictions = knn_classifier(train_data, validation_data, k)\n",
    "\n",
    "    test_labels = validation_data['decision'].values\n",
    "    accuracy_score = accuracy(test_labels, predictions)\n",
    "    accuracies.append(accuracy_score)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average Accuracy over {num_folds}-fold Cross-Validation with k={k}: {average_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
